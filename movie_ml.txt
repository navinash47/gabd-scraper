bs=64
n_factors=10
8, 5e-3, wd=0.1
epoch	train_loss	valid_loss	time
0	1.052168	1.012938	00:08
1	0.913259	0.884284	00:07
2	0.856795	0.855020	00:08
3	0.803896	0.836232	00:08
4	0.819917	0.824585	00:07
5	0.758449	0.815940	00:08
6	0.703403	0.812509	00:08
7	0.700515	0.812550	00:08

---------------------------------------------------------------------------
bs=64
n_factors=12
8, 5e-3, wd=0.1
epoch	train_loss	valid_loss	time
0	1.047173	1.008370	00:08
1	0.872920	0.876109	00:08
2	0.838788	0.840271	00:07
3	0.807932	0.828109	00:08
4	0.772551	0.814818	00:08
5	0.740770	0.807456	00:07
6	0.688460	0.805254	00:08
7	0.677595	0.805052	00:08

---------------------------------------------------------------------------
bs=64
n_factors=15
8, 5e-3, wd=0.1
epoch	train_loss	valid_loss	time
0	1.047166	0.994673	00:08
1	0.873111	0.875023	00:08
2	0.885483	0.853080	00:08
3	0.805929	0.831217	00:07
4	0.771530	0.812401	00:08
5	0.724254	0.805333	00:08
6	0.668175	0.803735	00:07
7	0.640053	0.803683	00:08

---------------------------------------------------------------------------
bs=64
n_factors=17
8, 5e-3, wd=0.1
epoch	train_loss	valid_loss	time
0	1.027137	0.983194	00:08
1	0.915544	0.881676	00:08
2	0.861446	0.851284	00:07
3	0.802535	0.829030	00:08
4	0.747499	0.811657	00:08
5	0.692131	0.804735	00:07
6	0.642622	0.803866	00:08
7	0.607174	0.803649	00:08

---------------------------------------------------------------------------
bs=64
n_factors=20
8, 5e-3, wd=0.1
epoch	train_loss	valid_loss	time
0	0.994198	0.972448	00:08
1	0.892372	0.880554	00:07
2	0.823217	0.853551	00:08
3	0.783185	0.829511	00:08
4	0.717275	0.809031	00:07
5	0.655305	0.804282	00:08
6	0.601653	0.804117	00:08
7	0.579756	0.804473	00:08

---------------------------------------------------------------------------
bs=64
n_factors=30
8, 5e-3, wd=0.1
epoch	train_loss	valid_loss	time
0	0.966361	0.966337	00:08
1	0.896208	0.878983	00:07
2	0.836613	0.845063	00:08
3	0.744299	0.819909	00:08
4	0.672714	0.813738	00:08
5	0.588139	0.811507	00:08
6	0.504246	0.813049	00:08
7	0.472942	0.813375	00:07

---------------------------------------------------------------------------
bs=64
n_factors=40
8, 5e-3, wd=0.1
epoch	train_loss	valid_loss	time
0	0.999286	0.956636	00:08
1	0.896793	0.879622	00:08
2	0.812765	0.838805	00:08
3	0.701075	0.826459	00:08
4	0.605850	0.821946	00:08
5	0.504665	0.825390	00:07
6	0.419665	0.829597	00:09
7	0.388550	0.830653	00:08

---------------------------------------------------------------------------
bs=64
n_factors=5, use_nn=True
20, 5e-3, wd=0.1
epoch	train_loss	valid_loss	time
0	0.950191	0.934433	00:09
1	0.924263	0.915929	00:09
2	0.938770	0.911825	00:09
3	0.924065	0.897647	00:08
4	0.922279	0.881590	00:09
5	0.861564	0.870679	00:09
6	0.886592	0.872626	00:09
7	0.855731	0.864391	00:08
8	0.864318	0.868003	00:09
9	0.859354	0.858614	00:09
10	0.842578	0.863951	00:09
11	0.816215	0.854255	00:09
12	0.802742	0.853504	00:09
13	0.809921	0.848650	00:09
14	0.786004	0.847096	00:09
15	0.770155	0.845578	00:09
16	0.742953	0.842107	00:08
17	0.696066	0.846277	00:09
18	0.693114	0.851625	00:09
19	0.660821	0.851876	00:09

---------------------------------------------------------------------------
bs=64
n_factors=10, use_nn=True
15, 5e-3, wd=0.1
epoch	train_loss	valid_loss	time
0	0.971240	0.949790	00:08
1	0.962057	0.913580	00:09
2	0.928218	0.910948	00:09
3	0.885650	0.881094	00:09
4	0.869461	0.874516	00:09
5	0.889613	0.869251	00:09
6	0.842203	0.854371	00:09
7	0.832933	0.858924	00:09
8	0.803490	0.851827	00:09
9	0.814806	0.846910	00:09
10	0.762758	0.842233	00:09
11	0.748325	0.842067	00:09
12	0.712613	0.848696	00:09
13	0.676030	0.860278	00:09
14	0.651103	0.859326	00:09

---------------------------------------------------------------------------
